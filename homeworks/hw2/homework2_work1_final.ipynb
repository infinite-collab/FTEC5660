{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      },
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3g3k3W-qfAv"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vsESFZylO6O"
      },
      "source": [
        "## Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrdfpmv9nMpw",
        "outputId": "86e08e98-fa9f-4dd5-d406-87ad416997f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: markitdown[pdf] in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.6.3)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Requirement already satisfied: pdfminer-six>=20251230 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (20251230)\n",
            "Requirement already satisfied: pdfplumber>=0.11.9 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.11.9)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.24.2)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (5.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Requirement already satisfied: langchain_mcp_adapters in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (4.2.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.15)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.64.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.23.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.13.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.6)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.1)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.1)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUav-7KdaY_W"
      },
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRbStil_qkQc"
      },
      "source": [
        "# Download sample CVs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCENjOq6owDd"
      },
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "c74faaae-8e58-439e-8f8f-39f556c2cb64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 13.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 10.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 7.66MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 61.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 47.8MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "a928a452-1698-4139-bae8-74a36500fd56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ðŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ðŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA2GvPWTQFt9"
      },
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbkH9xHXfmK"
      },
      "source": [
        "## Check which tools that the MCP server provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "a890ed82-50ff-415b-8ca0-15915afc32a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoe2-qfXl7r"
      },
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "8a7d47b7-97d4-40cf-c018-603312e2ba17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"I'll start by saying hello to Bao, then search for Alice on Facebook.\\n\\n\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 3181, 'total_tokens': 3241, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'deepseek-v3.2', 'system_fingerprint': None, 'id': 'chatcmpl-d4fa3a56-f200-987f-bbc2-e285aa535dff', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019ca28c-d34b-7480-9290-bb094a9dd8ae-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'call_dc53064f1f6d4e4d8c30f3c2', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 3181, 'output_tokens': 60, 'total_tokens': 3241, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ðŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "DEEPSEEK_API_KEY = userdata.get(\"DEEPSEEK_API_KEY\")\n",
        "llm = ChatOpenAI(\n",
        "  model=\"deepseek-v3.2-251201\",          # or \"deepseek-reasoner\"\n",
        "  api_key=DEEPSEEK_API_KEY,\n",
        "  base_url=\"https://api.zetatechs.com/v1\",\n",
        "  temperature=0,\n",
        " )\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Single-step invocation\n",
        "# ---------------------------\n",
        "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "ac28d1c2-a7bd-4f12-acda-12f40ce7537a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
              "  'id': 'lc_fa190d86-ff4c-4402-a76c-10073542ad1e'}]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "await tools[5].ainvoke({'person_id': 456})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqO99iOlq6mc"
      },
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "e6b625b2-3034-4c69-c534-d05d63688d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'decisions': [1, 1, 1, 0, 0], 'correct': 5, 'total': 5, 'final_score': 1.0}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import difflib\n",
        "import asyncio\n",
        "import logging\n",
        "\n",
        "_mcp_logger = logging.getLogger('mcp.client.streamable_http')\n",
        "_mcp_logger.setLevel(logging.CRITICAL)\n",
        "_mcp_logger.propagate = False\n",
        "logging.getLogger('mcp').setLevel(logging.CRITICAL)\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def _clamp01(x, default=0.5):\n",
        "    try:\n",
        "        x = float(x)\n",
        "    except Exception:\n",
        "        return float(default)\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "def _strip_code_fences(text):\n",
        "    text = (text or '').strip()\n",
        "    if not text.startswith('```'):\n",
        "        return text\n",
        "    lines = text.splitlines()\n",
        "    if lines and lines[0].startswith('```'):\n",
        "        lines = lines[1:]\n",
        "    if lines and lines[-1].startswith('```'):\n",
        "        lines = lines[:-1]\n",
        "    return chr(10).join(lines).strip()\n",
        "\n",
        "def _extract_json(text):\n",
        "    text = _strip_code_fences(text)\n",
        "    start = text.find('{')\n",
        "    end = text.rfind('}')\n",
        "    if start == -1 or end == -1 or end <= start:\n",
        "        raise ValueError('No JSON object found in LLM output')\n",
        "    return json.loads(text[start:end + 1])\n",
        "\n",
        "def _pick_tool(tool_list, *hints):\n",
        "    for hint in hints:\n",
        "        for t in tool_list:\n",
        "            if getattr(t, 'name', None) == hint:\n",
        "                return t\n",
        "    for hint in hints:\n",
        "        for t in tool_list:\n",
        "            if hint in getattr(t, 'name', ''):\n",
        "                return t\n",
        "    names = [getattr(t, 'name', None) for t in tool_list]\n",
        "    raise KeyError(f'Tool not found. Hints={hints}. Available={names}')\n",
        "\n",
        "_MCP_MAX_CONCURRENCY = int(os.getenv('MCP_MAX_CONCURRENCY', '1') or '1')\n",
        "_MCP_SEM = asyncio.Semaphore(max(1, _MCP_MAX_CONCURRENCY))\n",
        "\n",
        "def _unwrap_mcp_output(raw):\n",
        "    if raw is None:\n",
        "        return None\n",
        "\n",
        "    if isinstance(raw, list) and raw and isinstance(raw[0], dict) and 'text' in raw[0]:\n",
        "        txt = raw[0].get('text')\n",
        "        if isinstance(txt, str):\n",
        "            s = txt.strip()\n",
        "            if s and s[0] in '{[':\n",
        "                try:\n",
        "                    return json.loads(s)\n",
        "                except Exception:\n",
        "                    return raw\n",
        "\n",
        "    if isinstance(raw, dict) and 'text' in raw and isinstance(raw.get('text'), str):\n",
        "        s = raw['text'].strip()\n",
        "        if s and s[0] in '{[':\n",
        "            try:\n",
        "                return json.loads(s)\n",
        "            except Exception:\n",
        "                return raw\n",
        "\n",
        "    if isinstance(raw, str):\n",
        "        s = raw.strip()\n",
        "        if s and s[0] in '{[':\n",
        "            try:\n",
        "                return json.loads(s)\n",
        "            except Exception:\n",
        "                return raw\n",
        "\n",
        "    return raw\n",
        "\n",
        "def _is_transient_mcp_error(e: Exception) -> bool:\n",
        "\n",
        "    sub = getattr(e, 'exceptions', None)\n",
        "    if isinstance(sub, (list, tuple)) and sub:\n",
        "        for se in sub:\n",
        "            if isinstance(se, Exception) and _is_transient_mcp_error(se):\n",
        "                return True\n",
        "\n",
        "    name = type(e).__name__.lower()\n",
        "    msg = str(e).lower()\n",
        "    if 'server disconnected' in msg:\n",
        "        return True\n",
        "    if 'all connection attempts failed' in msg:\n",
        "        return True\n",
        "    if 'connection reset' in msg or 'reset by peer' in msg:\n",
        "        return True\n",
        "    if 'timed out' in msg or 'timeout' in msg:\n",
        "        return True\n",
        "    if 'remotep' in name or 'protocol' in name:\n",
        "        return True\n",
        "    if 'connect' in name and 'error' in name:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "async def _ainvoke_with_retry(tool, payload, default=None, retries=4, timeout_s=60, raise_on_fail=False):\n",
        "    last_exc = None\n",
        "    tool_name = getattr(tool, 'name', None)\n",
        "    for attempt in range(int(retries)):\n",
        "        try:\n",
        "            async with _MCP_SEM:\n",
        "                raw = await asyncio.wait_for(tool.ainvoke(payload), timeout=timeout_s)\n",
        "            return _unwrap_mcp_output(raw)\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            if _is_transient_mcp_error(e) and tool_name:\n",
        "                try:\n",
        "                    refreshed = await _ensure_tools(force_refresh=True)\n",
        "                    if refreshed:\n",
        "                        tool = _pick_tool(refreshed, tool_name)\n",
        "                except Exception:\n",
        "                    pass\n",
        "            if attempt < int(retries) - 1:\n",
        "                await asyncio.sleep(min(6.0, 0.75 * (2 ** attempt)))\n",
        "    if raise_on_fail and last_exc is not None:\n",
        "        raise last_exc\n",
        "    return default\n",
        "\n",
        "_md = None\n",
        "def _read_pdf_text(pdf_path):\n",
        "    global _md\n",
        "    try:\n",
        "        from markitdown import MarkItDown\n",
        "        if _md is None:\n",
        "            _md = MarkItDown(enable_plugins=False)\n",
        "        result = _md.convert(pdf_path)\n",
        "        return (getattr(result, 'text_content', None) or '').strip()\n",
        "    except Exception:\n",
        "        try:\n",
        "            import PyPDF2\n",
        "            reader = PyPDF2.PdfReader(pdf_path)\n",
        "            parts = []\n",
        "            for p in reader.pages:\n",
        "                parts.append(p.extract_text() or '')\n",
        "            return chr(10).join(parts).strip()\n",
        "        except Exception:\n",
        "            return ''\n",
        "\n",
        "def _cv_snippet(text, max_chars=12000):\n",
        "    text = text or ''\n",
        "    if len(text) <= max_chars:\n",
        "        return text\n",
        "    head = text[:8000]\n",
        "    tail = text[-4000:]\n",
        "    return head + chr(10) + '...' + chr(10) + tail\n",
        "\n",
        "def _find_cv_paths():\n",
        "    paths = []\n",
        "    for i in range(1, 6):\n",
        "        direct = [f'CV_{i}.pdf', os.path.join('downloaded_cvs', f'CV_{i}.pdf')]\n",
        "        found = None\n",
        "        for p in direct:\n",
        "            if os.path.exists(p):\n",
        "                found = p\n",
        "                break\n",
        "        if found is None:\n",
        "            for folder in ['.', 'downloaded_cvs']:\n",
        "                if not os.path.isdir(folder):\n",
        "                    continue\n",
        "                for fn in os.listdir(folder):\n",
        "                    if not fn.lower().endswith('.pdf'):\n",
        "                        continue\n",
        "                    digits = ''.join([ch for ch in fn if ch.isdigit()])\n",
        "                    if digits and digits.isdigit() and int(digits) == i:\n",
        "                        found = os.path.join(folder, fn)\n",
        "                        break\n",
        "                if found:\n",
        "                    break\n",
        "        if found is None:\n",
        "            raise FileNotFoundError(f'Missing CV_{i}.pdf (or equivalent) for i={i}')\n",
        "        paths.append(found)\n",
        "    return paths\n",
        "\n",
        "def _similarity(a, b):\n",
        "    a = (a or '').lower().strip()\n",
        "    b = (b or '').lower().strip()\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def _strip_parenthetical(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    out = []\n",
        "    depth = 0\n",
        "    for ch in text:\n",
        "        if ch == '(':\n",
        "            depth += 1\n",
        "            continue\n",
        "        if ch == ')' and depth:\n",
        "            depth -= 1\n",
        "            continue\n",
        "        if depth == 0:\n",
        "            out.append(ch)\n",
        "    return ''.join(out)\n",
        "\n",
        "def _tokenize_location(text):\n",
        "    text = _strip_parenthetical(text or '')\n",
        "    for sep in ['|', '/', ';', chr(10)]:\n",
        "        text = text.replace(sep, ',')\n",
        "    parts = [p.strip() for p in text.split(',')]\n",
        "\n",
        "    tokens = []\n",
        "    seen = set()\n",
        "    for p in parts:\n",
        "        if not p:\n",
        "            continue\n",
        "        p = ' '.join(p.split())\n",
        "        key = p.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        tokens.append(p)\n",
        "    return tokens\n",
        "\n",
        "def _location_candidates(candidate):\n",
        "    if not isinstance(candidate, dict):\n",
        "        return []\n",
        "    tokens = []\n",
        "    for k in ('city', 'country', 'location_query'):\n",
        "        tokens.extend(_tokenize_location(candidate.get(k)))\n",
        "    return tokens[:4]\n",
        "\n",
        "def _as_list(x):\n",
        "    if x is None:\n",
        "        return []\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    return [x]\n",
        "\n",
        "def _pick_str(x, *keys):\n",
        "    if isinstance(x, str) and x.strip():\n",
        "        return x.strip()\n",
        "    if isinstance(x, dict):\n",
        "        for k in keys:\n",
        "            v = x.get(k)\n",
        "            if isinstance(v, str) and v.strip():\n",
        "                return v.strip()\n",
        "    return None\n",
        "\n",
        "def _dedup_strings(items, limit=None):\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for s in items:\n",
        "        if not isinstance(s, str):\n",
        "            continue\n",
        "        s = s.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        key = s.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        out.append(s)\n",
        "        if limit and len(out) >= int(limit):\n",
        "            break\n",
        "    return out\n",
        "\n",
        "_YEAR_RE = re.compile(r'\\b(19|20)\\d{2}\\b')\n",
        "_YEAR_RANGE_RE = re.compile(r'\\b(19|20)\\d{2}\\s*[-â€“â€”]\\s*(?:present|current|now|\\d{2,4})\\b', re.IGNORECASE)\n",
        "\n",
        "def _strip_year_tokens(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    t = text\n",
        "    t = _YEAR_RANGE_RE.sub('', t)\n",
        "    t = _YEAR_RE.sub('', t)\n",
        "    t = re.sub(r'\\b(graduated|present|current|now)\\b', '', t, flags=re.IGNORECASE)\n",
        "    t = t.replace('â€“', ' ').replace('â€”', ' ').replace('-', ' ')\n",
        "    return ' '.join(t.split()).strip()\n",
        "\n",
        "def _extract_company_from_experience_line(line):\n",
        "    if not isinstance(line, str):\n",
        "        return None\n",
        "    s = ' '.join(line.replace(chr(10), ' ').split()).strip()\n",
        "    if not s:\n",
        "        return None\n",
        "\n",
        "    company = None\n",
        "    if ',' in s:\n",
        "        parts = [p.strip() for p in s.split(',') if p.strip()]\n",
        "        if len(parts) >= 2:\n",
        "            company = parts[1]\n",
        "    else:\n",
        "        m = re.search(r'\\b(?:at|@)\\s+([A-Z][\\w& .-]{1,80})\\b', s)\n",
        "        if m:\n",
        "            company = m.group(1)\n",
        "\n",
        "    company = _strip_year_tokens(company) if company else ''\n",
        "    company = company.strip(' .|/')\n",
        "    if not company:\n",
        "        return None\n",
        "\n",
        "    if len(company) > 80:\n",
        "        return None\n",
        "\n",
        "    if _YEAR_RE.search(company):\n",
        "        company = _YEAR_RE.sub('', company).strip()\n",
        "\n",
        "    return company or None\n",
        "\n",
        "def _extract_school_from_education_line(line):\n",
        "    if not isinstance(line, str):\n",
        "        return None\n",
        "    s = ' '.join(line.replace(chr(10), ' ').split()).strip()\n",
        "    if not s:\n",
        "        return None\n",
        "\n",
        "    school = None\n",
        "    if ',' in s:\n",
        "        parts = [p.strip() for p in s.split(',') if p.strip()]\n",
        "        for p in parts:\n",
        "            if re.search(r'(university|college|institute|school|polyu|nus|hku)', p, flags=re.IGNORECASE):\n",
        "                school = p\n",
        "                break\n",
        "        if school is None and len(parts) >= 2:\n",
        "            school = parts[1]\n",
        "    else:\n",
        "        m = re.search(r'([A-Z][A-Za-z& .-]{2,80}(?:University|College|Institute|School))\\b', s)\n",
        "        if m:\n",
        "            school = m.group(1)\n",
        "\n",
        "    school = _strip_year_tokens(school) if school else ''\n",
        "    school = school.strip(' .|/')\n",
        "    if not school or len(school) > 100:\n",
        "        return None\n",
        "    return school\n",
        "\n",
        "def _candidate_companies(candidate):\n",
        "    if not isinstance(candidate, dict):\n",
        "        return []\n",
        "    companies = []\n",
        "    cc = _pick_str(candidate.get('current_company'))\n",
        "    if cc:\n",
        "        companies.append(cc)\n",
        "    for item in _as_list(candidate.get('experience')):\n",
        "        if isinstance(item, dict):\n",
        "            c = _pick_str(item, 'company', 'organization', 'employer')\n",
        "            if c:\n",
        "                companies.append(c)\n",
        "        elif isinstance(item, str):\n",
        "            c = _extract_company_from_experience_line(item)\n",
        "            if c:\n",
        "                companies.append(c)\n",
        "    return _dedup_strings(companies, limit=8)\n",
        "\n",
        "def _candidate_schools(candidate):\n",
        "    if not isinstance(candidate, dict):\n",
        "        return []\n",
        "    schools = []\n",
        "    for item in _as_list(candidate.get('education')):\n",
        "        if isinstance(item, dict):\n",
        "            s = _pick_str(item, 'school', 'university', 'institution', 'name')\n",
        "            if s:\n",
        "                schools.append(s)\n",
        "        elif isinstance(item, str):\n",
        "            s = _extract_school_from_education_line(item)\n",
        "            if s:\n",
        "                schools.append(s)\n",
        "    return _dedup_strings(schools, limit=8)\n",
        "\n",
        "def _candidate_skills(candidate):\n",
        "    if not isinstance(candidate, dict):\n",
        "        return []\n",
        "    skills = []\n",
        "    for item in _as_list(candidate.get('skills')):\n",
        "        s = _pick_str(item, 'name', 'skill')\n",
        "        if s:\n",
        "            skills.append(s)\n",
        "    return _dedup_strings(skills, limit=12)\n",
        "\n",
        "def _linkedin_companies(profile):\n",
        "    if not isinstance(profile, dict):\n",
        "        return []\n",
        "    companies = []\n",
        "    for e in _as_list(profile.get('experience')):\n",
        "        c = _pick_str(e, 'company')\n",
        "        if c:\n",
        "            companies.append(c)\n",
        "    return _dedup_strings(companies, limit=12)\n",
        "\n",
        "def _linkedin_schools(profile):\n",
        "    if not isinstance(profile, dict):\n",
        "        return []\n",
        "    schools = []\n",
        "    for e in _as_list(profile.get('education')):\n",
        "        s = _pick_str(e, 'school')\n",
        "        if s:\n",
        "            schools.append(s)\n",
        "    return _dedup_strings(schools, limit=12)\n",
        "\n",
        "def _linkedin_skills(profile):\n",
        "    if not isinstance(profile, dict):\n",
        "        return []\n",
        "    skills = []\n",
        "    for item in _as_list(profile.get('skills')):\n",
        "        s = _pick_str(item, 'name')\n",
        "        if s:\n",
        "            skills.append(s)\n",
        "    return _dedup_strings(skills, limit=20)\n",
        "\n",
        "def _max_similarity(list_a, list_b):\n",
        "    best = 0.0\n",
        "    for a in list_a:\n",
        "        for b in list_b:\n",
        "            best = max(best, _similarity(a, b))\n",
        "    return float(best)\n",
        "\n",
        "def _consistency_linkedin(candidate, profile):\n",
        "    if not isinstance(candidate, dict) or not isinstance(profile, dict):\n",
        "        return 0.5\n",
        "\n",
        "    score = 0.5\n",
        "\n",
        "    cand_companies = _candidate_companies(candidate)\n",
        "    prof_companies = _linkedin_companies(profile)\n",
        "    if cand_companies and prof_companies:\n",
        "        m = _max_similarity(cand_companies, prof_companies)\n",
        "        score += 0.25 if m >= 0.86 else -0.25\n",
        "\n",
        "    cand_schools = _candidate_schools(candidate)\n",
        "    prof_schools = _linkedin_schools(profile)\n",
        "    if cand_schools and prof_schools:\n",
        "        m = _max_similarity(cand_schools, prof_schools)\n",
        "        score += 0.20 if m >= 0.86 else -0.20\n",
        "\n",
        "    ct = _pick_str(candidate.get('current_title'))\n",
        "    headline = _pick_str(profile.get('headline'))\n",
        "    if ct and headline:\n",
        "        m = _similarity(ct, headline)\n",
        "        if m >= 0.75:\n",
        "            score += 0.10\n",
        "        elif m <= 0.35:\n",
        "            score -= 0.10\n",
        "\n",
        "    cand_city = _pick_str(candidate.get('city'))\n",
        "    cand_country = _pick_str(candidate.get('country'))\n",
        "    prof_city = _pick_str(profile.get('city'))\n",
        "    prof_country = _pick_str(profile.get('country'))\n",
        "    if cand_city and prof_city and _similarity(cand_city, prof_city) >= 0.85:\n",
        "        score += 0.05\n",
        "    if cand_country and prof_country and _similarity(cand_country, prof_country) >= 0.85:\n",
        "        score += 0.03\n",
        "\n",
        "    cand_skills = _candidate_skills(candidate)\n",
        "    prof_skills = _linkedin_skills(profile)\n",
        "    if cand_skills and prof_skills:\n",
        "        m = _max_similarity(cand_skills, prof_skills)\n",
        "        if m >= 0.86:\n",
        "            score += 0.05\n",
        "\n",
        "    return _clamp01(score, default=0.5)\n",
        "\n",
        "def _consistency_facebook(candidate, profile):\n",
        "    if not isinstance(candidate, dict) or not isinstance(profile, dict):\n",
        "        return 0.5\n",
        "\n",
        "    score = 0.5\n",
        "\n",
        "    cand_city = _pick_str(candidate.get('city'))\n",
        "    cand_country = _pick_str(candidate.get('country'))\n",
        "    fb_city = _pick_str(profile.get('city'))\n",
        "    fb_country = _pick_str(profile.get('country'))\n",
        "    if cand_city and fb_city and _similarity(cand_city, fb_city) >= 0.85:\n",
        "        score += 0.10\n",
        "    if cand_country and fb_country and _similarity(cand_country, fb_country) >= 0.85:\n",
        "        score += 0.05\n",
        "\n",
        "    cand_company = _pick_str(candidate.get('current_company'))\n",
        "    fb_company = _pick_str(profile.get('current_company'))\n",
        "    if cand_company and fb_company:\n",
        "        m = _similarity(cand_company, fb_company)\n",
        "        score += 0.25 if m >= 0.86 else -0.25\n",
        "\n",
        "    ct = _pick_str(candidate.get('current_title'))\n",
        "    fb_job = _pick_str(profile.get('current_job'))\n",
        "    if ct and fb_job:\n",
        "        m = _similarity(ct, fb_job)\n",
        "        if m >= 0.70:\n",
        "            score += 0.10\n",
        "        elif m <= 0.35:\n",
        "            score -= 0.05\n",
        "\n",
        "    return _clamp01(score, default=0.5)\n",
        "\n",
        "def _compact_linkedin(profile):\n",
        "    if not isinstance(profile, dict):\n",
        "        return profile\n",
        "    keys = [\n",
        "        'id', 'name', 'headline', 'city', 'country', 'industry', 'status',\n",
        "        'years_experience', 'summary', 'skills', 'experience', 'education'\n",
        "    ]\n",
        "    return {k: profile.get(k) for k in keys}\n",
        "\n",
        "def _compact_facebook(profile):\n",
        "    if not isinstance(profile, dict):\n",
        "        return profile\n",
        "    keys = [\n",
        "        'id', 'display_name', 'original_name', 'city', 'country', 'hometown',\n",
        "        'bio', 'status', 'education', 'current_job', 'current_company',\n",
        "        'interests', 'friend_count'\n",
        "    ]\n",
        "    return {k: profile.get(k) for k in keys}\n",
        "\n",
        "def _compact_interactions(interactions):\n",
        "    if not isinstance(interactions, dict):\n",
        "        return interactions\n",
        "    keys = ['profile_id', 'post_count', 'total_likes', 'engagement_score']\n",
        "    return {k: interactions.get(k) for k in keys}\n",
        "\n",
        "def _ensure_llm():\n",
        "    if globals().get('llm') is not None:\n",
        "        return globals()['llm']\n",
        "\n",
        "    api_key = globals().get('GEMINI_VERTEX_API_KEY') or os.getenv('VERTEX_API_KEY') or os.getenv('GEMINI_API_KEY')\n",
        "    if api_key:\n",
        "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "        return ChatGoogleGenerativeAI(model='gemini-2.0-flash', google_api_key=api_key, temperature=0)\n",
        "\n",
        "    api_key = globals().get('DEEPSEEK_API_KEY') or os.getenv('DEEPSEEK_API_KEY')\n",
        "    if api_key:\n",
        "        from langchain_openai import ChatOpenAI\n",
        "        return ChatOpenAI(\n",
        "            model='deepseek-chat',\n",
        "            api_key=api_key,\n",
        "            base_url='https://api.deepseek.com/v1',\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    raise RuntimeError('No LLM API key found. Set VERTEX_API_KEY or DEEPSEEK_API_KEY.')\n",
        "\n",
        "async def _ensure_tools(force_refresh=False):\n",
        "    if not force_refresh and isinstance(globals().get('tools'), list) and globals()['tools']:\n",
        "        return globals()['tools']\n",
        "    from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "    mcp_url = os.getenv('SOCIAL_GRAPH_MCP_URL', 'https://ftec5660.ngrok.app/mcp')\n",
        "    client = MultiServerMCPClient({\n",
        "        'social_graph': {\n",
        "            'transport': 'http',\n",
        "            'url': mcp_url,\n",
        "            'headers': {'ngrok-skip-browser-warning': 'true'},\n",
        "        }\n",
        "    })\n",
        "    last_exc = None\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            loaded = await asyncio.wait_for(client.get_tools(), timeout=30)\n",
        "            globals()['tools'] = loaded\n",
        "            return loaded\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            if attempt < 2:\n",
        "                await asyncio.sleep(min(6.0, 0.75 * (2 ** attempt)))\n",
        "    print(f\"WARNING: cannot connect to MCP server at {mcp_url}: {last_exc}\")\n",
        "    return []\n",
        "\n",
        "async def _extract_candidate(llm, cv_text):\n",
        "    prompt = f'''\n",
        "You are a KYC/recruiting verifier. Extract structured candidate information from the CV text.\n",
        "\n",
        "Return ONLY a valid JSON object with keys:\n",
        "full_name, name_variants, city, country, location_query, current_title, current_company,\n",
        "education, experience, skills, keywords.\n",
        "\n",
        "Rules:\n",
        "- Use null if unknown\n",
        "- Years must be integers or null\n",
        "- Keep lists short (<= 6 items)\n",
        "- name_variants should include likely variants of the name (<= 4)\n",
        "\n",
        "CV_TEXT:\n",
        "```\n",
        "{_cv_snippet(cv_text)}\n",
        "```\n",
        "'''.strip()\n",
        "\n",
        "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = getattr(resp, 'content', '') if resp is not None else ''\n",
        "    try:\n",
        "        data = _extract_json(content)\n",
        "    except Exception:\n",
        "        data = {\n",
        "            'full_name': None,\n",
        "            'name_variants': [],\n",
        "            'city': None,\n",
        "            'country': None,\n",
        "            'location_query': None,\n",
        "            'current_title': None,\n",
        "            'current_company': None,\n",
        "            'education': [],\n",
        "            'experience': [],\n",
        "            'skills': [],\n",
        "            'keywords': [],\n",
        "        }\n",
        "\n",
        "    if not isinstance(data.get('name_variants'), list):\n",
        "        data['name_variants'] = []\n",
        "    if data.get('full_name') and data['full_name'] not in data['name_variants']:\n",
        "        data['name_variants'] = [data['full_name']] + data['name_variants']\n",
        "    data['name_variants'] = [x for x in data['name_variants'] if isinstance(x, str) and x.strip()][:4]\n",
        "\n",
        "    if not data.get('full_name'):\n",
        "        for line in (cv_text or '').splitlines():\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            line_clean = line.replace('Name:', '').replace('å§“åï¼š', '').strip()\n",
        "            if 2 <= len(line_clean) <= 80:\n",
        "                data['full_name'] = line_clean\n",
        "                if line_clean not in data['name_variants']:\n",
        "                    data['name_variants'] = [line_clean] + data['name_variants']\n",
        "                break\n",
        "\n",
        "    return data\n",
        "\n",
        "async def _choose_id_with_llm(llm, candidate, platform, options):\n",
        "    prompt = f'''\n",
        "You are matching a CV to a {platform} search result.\n",
        "\n",
        "Candidate (from CV extraction):\n",
        "{json.dumps(candidate, ensure_ascii=False)}\n",
        "\n",
        "{platform} search options:\n",
        "{json.dumps(options, ensure_ascii=False)}\n",
        "\n",
        "Return ONLY JSON with keys: id (int or null), reason (string).\n",
        "Choose null if none match reasonably.\n",
        "'''.strip()\n",
        "\n",
        "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = getattr(resp, 'content', '') if resp is not None else ''\n",
        "    try:\n",
        "        out = _extract_json(content)\n",
        "        return out.get('id', None)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "async def _best_linkedin(tools, llm, candidate):\n",
        "    try:\n",
        "        search = _pick_tool(tools, 'search_linkedin_people', 'linkedin_people', 'search_linkedin')\n",
        "        get_profile = _pick_tool(tools, 'get_linkedin_profile', 'linkedin_profile', 'get_linkedin')\n",
        "        get_interactions = _pick_tool(tools, 'get_linkedin_interactions', 'linkedin_interactions', 'get_interactions')\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    queries = []\n",
        "    if candidate.get('name_variants'):\n",
        "        queries.extend(candidate['name_variants'])\n",
        "    if candidate.get('full_name'):\n",
        "        queries.insert(0, candidate['full_name'])\n",
        "    if candidate.get('keywords'):\n",
        "        queries.extend(candidate['keywords'][:2])\n",
        "\n",
        "    seen = set()\n",
        "    queries = [q for q in queries if isinstance(q, str) and q.strip() and not (q in seen or seen.add(q))]\n",
        "    queries = queries[:4]\n",
        "\n",
        "    location_candidates = _location_candidates(candidate)\n",
        "\n",
        "    results = []\n",
        "    for q in queries:\n",
        "        r = []\n",
        "        for loc in location_candidates:\n",
        "            payload = {'q': q, 'location': loc, 'limit': 20, 'fuzzy': True}\n",
        "            try:\n",
        "                r = await _ainvoke_with_retry(search, payload, default=[], retries=3, timeout_s=60, raise_on_fail=True)\n",
        "            except Exception:\n",
        "                r = await _ainvoke_with_retry(search, payload, default=[], retries=2, timeout_s=60)\n",
        "            if isinstance(r, list) and r:\n",
        "                break\n",
        "        if not r:\n",
        "            payload = {'q': q, 'limit': 20, 'fuzzy': True}\n",
        "            try:\n",
        "                r = await _ainvoke_with_retry(search, payload, default=[], retries=3, timeout_s=60, raise_on_fail=True)\n",
        "            except Exception:\n",
        "                r = await _ainvoke_with_retry(search, payload, default=[], retries=2, timeout_s=60)\n",
        "        if isinstance(r, list):\n",
        "            results.extend(r)\n",
        "\n",
        "    seen_ids = set()\n",
        "    dedup = []\n",
        "    for r in results:\n",
        "        if not isinstance(r, dict):\n",
        "            continue\n",
        "        rid = r.get('id')\n",
        "        if rid is None or rid in seen_ids:\n",
        "            continue\n",
        "        seen_ids.add(rid)\n",
        "        dedup.append(r)\n",
        "    if not dedup:\n",
        "        return None\n",
        "\n",
        "    target_name = candidate.get('full_name') or (candidate.get('name_variants') or [None])[0]\n",
        "    target_city = (candidate.get('city') or '').lower()\n",
        "    target_country = (candidate.get('country') or '').lower()\n",
        "    target_title = candidate.get('current_title') or ''\n",
        "\n",
        "    scored = []\n",
        "    for r in dedup:\n",
        "        name = r.get('name') or ''\n",
        "        loc = (r.get('location') or '').lower()\n",
        "        s = 0.75 * _similarity(target_name, name)\n",
        "        if target_city and target_city in loc:\n",
        "            s += 0.10\n",
        "        if target_country and target_country in loc:\n",
        "            s += 0.15\n",
        "        scored.append((s, r))\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    top5 = [r for _, r in scored[:5]]\n",
        "    chosen_id = top5[0].get('id')\n",
        "\n",
        "    if len(top5) >= 2:\n",
        "        s0, s1 = scored[0][0], scored[1][0]\n",
        "        if s0 < 0.85 and abs(s0 - s1) < 0.06:\n",
        "            llm_id = await _choose_id_with_llm(llm, candidate, 'LinkedIn', top5)\n",
        "            if isinstance(llm_id, int):\n",
        "                chosen_id = llm_id\n",
        "\n",
        "    if chosen_id is None:\n",
        "        return None\n",
        "\n",
        "\n",
        "    top_for_profiles = [r for _, r in scored[:12]]\n",
        "    candidate_ids = [r.get('id') for r in top_for_profiles if r.get('id') is not None][:8]\n",
        "    if not candidate_ids:\n",
        "        candidate_ids = [chosen_id]\n",
        "    prof_tasks = [\n",
        "        _ainvoke_with_retry(get_profile, {'person_id': int(pid)}, default=None, retries=2, timeout_s=60)\n",
        "        for pid in candidate_ids\n",
        "    ]\n",
        "    profiles = await asyncio.gather(*prof_tasks, return_exceptions=True)\n",
        "\n",
        "    best_id = None\n",
        "    best_profile = None\n",
        "    best_match = -1.0\n",
        "    for pid, prof in zip(candidate_ids, profiles):\n",
        "        if isinstance(prof, Exception) or not isinstance(prof, dict):\n",
        "            continue\n",
        "        ms = _consistency_linkedin(candidate, prof)\n",
        "        if ms > best_match:\n",
        "            best_id = pid\n",
        "            best_profile = prof\n",
        "            best_match = ms\n",
        "\n",
        "    if best_id is None:\n",
        "        best_id = chosen_id\n",
        "        best_profile = await _ainvoke_with_retry(get_profile, {'person_id': int(best_id)}, default=None, retries=2, timeout_s=60)\n",
        "        best_match = _consistency_linkedin(candidate, best_profile) if isinstance(best_profile, dict) else 0.5\n",
        "\n",
        "    if not isinstance(best_profile, dict) or best_match < 0.55:\n",
        "        return None\n",
        "\n",
        "    interactions = await _ainvoke_with_retry(get_interactions, {'person_id': int(best_id)}, default=None, retries=2, timeout_s=60)\n",
        "\n",
        "    return {\n",
        "        'person_id': int(best_id),\n",
        "        'profile': best_profile,\n",
        "        'interactions': interactions,\n",
        "        'match_score': float(best_match),\n",
        "    }\n",
        "\n",
        "async def _best_facebook(tools, llm, candidate):\n",
        "    try:\n",
        "        search = _pick_tool(tools, 'search_facebook_users', 'facebook_users', 'search_facebook')\n",
        "        get_profile = _pick_tool(tools, 'get_facebook_profile', 'facebook_profile', 'get_facebook')\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    queries = []\n",
        "    if candidate.get('name_variants'):\n",
        "        queries.extend(candidate['name_variants'])\n",
        "    if candidate.get('full_name'):\n",
        "        queries.insert(0, candidate['full_name'])\n",
        "\n",
        "    seen = set()\n",
        "    queries = [q for q in queries if isinstance(q, str) and q.strip() and not (q in seen or seen.add(q))]\n",
        "    queries = queries[:3]\n",
        "\n",
        "    results = []\n",
        "    for q in queries:\n",
        "        try:\n",
        "            r = await _ainvoke_with_retry(search, {'q': q, 'limit': 20, 'fuzzy': True}, default=[], retries=3, timeout_s=60, raise_on_fail=True)\n",
        "        except Exception:\n",
        "            r = await _ainvoke_with_retry(search, {'q': q, 'limit': 20}, default=[], retries=2, timeout_s=60)\n",
        "        if isinstance(r, list):\n",
        "            results.extend(r)\n",
        "\n",
        "    seen_ids = set()\n",
        "    dedup = []\n",
        "    for r in results:\n",
        "        if not isinstance(r, dict):\n",
        "            continue\n",
        "        rid = r.get('id')\n",
        "        if rid is None or rid in seen_ids:\n",
        "            continue\n",
        "        seen_ids.add(rid)\n",
        "        dedup.append(r)\n",
        "    if not dedup:\n",
        "        return None\n",
        "\n",
        "    target_name = candidate.get('full_name') or (candidate.get('name_variants') or [None])[0]\n",
        "    target_country = (candidate.get('country') or '').lower()\n",
        "\n",
        "    scored = []\n",
        "    for r in dedup:\n",
        "        name = r.get('display_name') or ''\n",
        "        city = (r.get('city') or '').lower()\n",
        "        country = (r.get('country') or '').lower()\n",
        "        s = 0.70 * _similarity(target_name, name)\n",
        "        if target_city and target_city == city:\n",
        "            s += 0.15\n",
        "        if target_country and target_country == country:\n",
        "            s += 0.15\n",
        "        scored.append((s, r))\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    top = [r for _, r in scored[:8]]\n",
        "    chosen_id = top[0].get('id')\n",
        "\n",
        "    if len(top) >= 2:\n",
        "        s0, s1 = scored[0][0], scored[1][0]\n",
        "        if s0 < 0.85 and abs(s0 - s1) < 0.06:\n",
        "            llm_id = await _choose_id_with_llm(llm, candidate, 'Facebook', top)\n",
        "            if isinstance(llm_id, int):\n",
        "                chosen_id = llm_id\n",
        "\n",
        "    if chosen_id is None:\n",
        "        return None\n",
        "\n",
        "    candidate_ids = [r.get('id') for r in top if r.get('id') is not None][:5]\n",
        "    prof_tasks = [\n",
        "        _ainvoke_with_retry(get_profile, {'user_id': int(uid)}, default=None, retries=2, timeout_s=60)\n",
        "        for uid in candidate_ids\n",
        "    ]\n",
        "    profiles = await asyncio.gather(*prof_tasks, return_exceptions=True)\n",
        "\n",
        "    best_id = None\n",
        "    best_profile = None\n",
        "    best_match = -1.0\n",
        "    for uid, prof in zip(candidate_ids, profiles):\n",
        "        if isinstance(prof, Exception) or not isinstance(prof, dict):\n",
        "            continue\n",
        "        ms = _consistency_facebook(candidate, prof)\n",
        "        if ms > best_match:\n",
        "            best_id = uid\n",
        "            best_profile = prof\n",
        "            best_match = ms\n",
        "\n",
        "    if best_id is None or best_profile is None:\n",
        "        return None\n",
        "\n",
        "    if best_match < 0.55:\n",
        "        return None\n",
        "    return {\n",
        "        'user_id': int(best_id),\n",
        "        'profile': best_profile,\n",
        "        'match_score': float(best_match),\n",
        "    }\n",
        "\n",
        "async def _score_one_cv(tools, llm, cv_text):\n",
        "    candidate = await _extract_candidate(llm, cv_text)\n",
        "\n",
        "    linkedin, facebook = await asyncio.gather(\n",
        "        _best_linkedin(tools, llm, candidate),\n",
        "        _best_facebook(tools, llm, candidate),\n",
        "        return_exceptions=True,\n",
        "    )\n",
        "    if isinstance(linkedin, Exception):\n",
        "        linkedin = None\n",
        "    if isinstance(facebook, Exception):\n",
        "        facebook = None\n",
        "\n",
        "    linkedin_profile = None if not linkedin else linkedin.get('profile')\n",
        "    facebook_profile = None if not facebook else facebook.get('profile')\n",
        "\n",
        "    rule_score = 0.45\n",
        "    if isinstance(linkedin_profile, dict):\n",
        "        rule_score = _consistency_linkedin(candidate, linkedin_profile)\n",
        "    elif isinstance(facebook_profile, dict):\n",
        "        rule_score = _consistency_facebook(candidate, facebook_profile)\n",
        "\n",
        "    fb_match = 0.0 if not facebook else float(facebook.get('match_score', 0.0) or 0.0)\n",
        "\n",
        "    evidence = {\n",
        "        'cv_extracted': candidate,\n",
        "        'linkedin': None if not linkedin else {\n",
        "            'person_id': linkedin.get('person_id'),\n",
        "            'profile': _compact_linkedin(linkedin.get('profile')),\n",
        "            'interactions': _compact_interactions(linkedin.get('interactions')),\n",
        "            'match_score': linkedin.get('match_score'),\n",
        "        },\n",
        "        'facebook': None if (not facebook or fb_match < 0.60) else {\n",
        "            'user_id': facebook.get('user_id'),\n",
        "            'profile': _compact_facebook(facebook.get('profile')),\n",
        "            'match_score': facebook.get('match_score'),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    prompt = f'''\n",
        "You are verifying whether a CV is consistent with public social profiles.\n",
        "\n",
        "Given the evidence JSON below, judge if the CV is reliable.\n",
        "\n",
        "Return ONLY JSON with keys:\n",
        "- score: float from 0 to 1\n",
        "- verdict: one of reliable, problematic, uncertain\n",
        "- key_findings: a short list of strings (max 6)\n",
        "\n",
        "Guidelines:\n",
        "- score > 0.5 means likely reliable\n",
        "- Penalize clear contradictions in education, employers, titles, timelines, or location\n",
        "- Do not heavily penalize missing data; treat missing as uncertainty\n",
        "- If no match is found, verdict is often uncertain and score should be around 0.45 unless there are obvious red flags\n",
        "- Facebook matches can be noisy; if facebook.match_score < 0.6, treat it as a likely wrong match and do not penalize the CV heavily\n",
        "\n",
        "Evidence:\n",
        "{json.dumps(evidence, ensure_ascii=False)}\n",
        "'''.strip()\n",
        "\n",
        "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = getattr(resp, 'content', '') if resp is not None else ''\n",
        "\n",
        "    score = 0.5\n",
        "    verdict = 'uncertain'\n",
        "    key_findings = []\n",
        "\n",
        "    try:\n",
        "        out = _extract_json(content)\n",
        "        score = _clamp01(out.get('score', 0.5))\n",
        "        verdict = out.get('verdict', verdict)\n",
        "        key_findings = out.get('key_findings', key_findings)\n",
        "        if not isinstance(key_findings, list):\n",
        "            key_findings = []\n",
        "    except Exception:\n",
        "        score = 0.5\n",
        "\n",
        "    score = _clamp01(0.6 * rule_score + 0.4 * score, default=rule_score)\n",
        "\n",
        "    details = {\n",
        "        'candidate': candidate,\n",
        "        'linkedin_person_id': None if not linkedin else linkedin.get('person_id'),\n",
        "        'facebook_user_id': None if not facebook else facebook.get('user_id'),\n",
        "        'verdict': verdict,\n",
        "        'key_findings': key_findings[:6],\n",
        "        'rule_score': rule_score,\n",
        "    }\n",
        "    return score, details\n",
        "\n",
        "async def generate_scores():\n",
        "    tools_local = await _ensure_tools()\n",
        "    llm_local = _ensure_llm()\n",
        "\n",
        "    cv_paths = _find_cv_paths()\n",
        "    cv_texts = [_read_pdf_text(p) for p in cv_paths]\n",
        "\n",
        "    scores_local = []\n",
        "    global verification_details\n",
        "    verification_details = []\n",
        "\n",
        "    for path, text in zip(cv_paths, cv_texts):\n",
        "        try:\n",
        "            s, detail = await _score_one_cv(tools_local, llm_local, text)\n",
        "        except Exception as e:\n",
        "            s = 0.5\n",
        "            detail = {\n",
        "                'candidate': {},\n",
        "                'linkedin_person_id': None,\n",
        "                'facebook_user_id': None,\n",
        "                'verdict': 'uncertain',\n",
        "                'key_findings': [f'exception: {e}'],\n",
        "            }\n",
        "        scores_local.append(_clamp01(s))\n",
        "        detail['file'] = path\n",
        "        detail['score'] = _clamp01(s)\n",
        "        verification_details.append(detail)\n",
        "\n",
        "    return scores_local\n",
        "\n",
        "scores = await generate_scores()\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
